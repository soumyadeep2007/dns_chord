import bisect
import hashlib
import random
import pickle

import os
from cffi.backend_ctypes import xrange

m_Resolver = import_da('resolver')
m_Node = import_da('node')


def _calculate_id(key, m):
    h = int(hashlib.sha1(key.encode('utf-8')).hexdigest(), 16)
    id = h % (1 << m)
    return id


def _get_records_for_node(node_index, record_ids_sorted, node_ids_sorted, records_by_id):
    #  distributed records for each node
    lo_id = node_ids_sorted[node_index - 1]
    hi_id = node_ids_sorted[node_index]

    lo = bisect.bisect_left(record_ids_sorted, lo_id)
    if node_ids_sorted[node_index - 1] == record_ids_sorted[lo]:
        lo += 1

    records = {}
    if lo_id <= hi_id:
        i = lo
        while record_ids_sorted[i] <= hi_id:
            record_id = record_ids_sorted[i]
            records[record_id] = records_by_id[record_id]
            i += 1

    else:
        for i in range(lo, len(record_ids_sorted)):
            record_id = record_ids_sorted[i]
            records[record_id] = records_by_id[record_id]
        i = 0
        while record_ids_sorted[i] <= hi_id:
            record_id = record_ids_sorted[i]
            records[record_id] = records_by_id[record_id]
            i += 1

    return records


def _get_finger(node_index, m, node_descs, node_ids_sorted):
    #  construct the finger table for a specific node
    id = node_ids_sorted[node_index]
    finger = []
    for i in range(0, m):
        inc = 1 << i
        index = bisect.bisect_left(node_ids_sorted, (id + inc) % (1 << m))
        finger.append(node_descs[index % len(node_descs)])
    return finger


def get_records_array(filename):
    """
    Get records from array
    :param filename: filename which to read. It must have 'name value' pairs seperated by space.
    :return: Return an array
    """
    records = []
    with open(file=filename) as file:
        for ln in file.readlines():
            records.append(tuple(ln.strip().split(' ')))

    return records

def sleepTimes():
    """
    Get time distribution from pickle
    :param None
    :return: Return an kde distribution
    """
    inp_file = open("kernel_density_model.pickle", "rb")
    kde = pickle.load(inp_file)
    return kde

def main():
    # m = 6
    # records = [
    #     ('a.com', '192.45.1.2'),
    #     ('b.edu', '192.45.1.2'),
    #     ('c.org', '192.49.1.20'),
    #     ('d.tb', '194.45.12.2'),
    #     ('www.google.com', '192.45.1.212'),
    #     ('mail.stony.edu', '192.45.111.2'),
    #     ('o.com', '194.45.1.26'),
    #     ('t.com', '193.41.1.2'),
    #     ('e.com', '199.42.1.12'),
    #     ('f.com', '190.45.1.33')
    # ]
    records = get_records_array('data/dns_records.txt')
    kde = sleepTimes()
    m = 20
    # m = ceil(log(len(records), 2))

    records_by_id = {_calculate_id(record[0], m): record for record in records}
    record_ids_sorted = list(records_by_id.keys())
    record_ids_sorted.sort()
    # node_ips = ['1.2.3.5', '2.3.4.5', '11.22.33.55', '8.8.8.9', '2.22.1.2', '77.66.3.1']
    node_ips = ['1.2.3.5', '2.3.4.5', '11.22.33.55', '8.8.8.9', '2.22.1.2', '77.66.3.1',
                '1.2.3.6', '2.3.4.6', '11.22.33.56', '8.8.8.10', '2.22.1.3', '77.66.3.2',
                '1.2.3.7', '2.3.4.7', '11.22.33.57', '8.8.8.11', '2.22.1.4', '77.66.3.3',
                '1.2.3.8', '2.3.4.8', '11.22.33.58', '8.8.8.12', '2.22.1.5', '77.66.3.4',
                '1.2.3.9', '2.3.4.9', '11.22.33.59', '8.8.8.13', '2.22.1.6', '77.66.3.5']
    node_ips_by_id = {_calculate_id(node_ip, m): node_ip for node_ip in node_ips}
    node_ids_sorted = list(node_ips_by_id.keys())
    print('len(node_ids_sorted) = ', len(node_ids_sorted))
    node_ids_sorted.sort()
    # workload = ['a.com', 't.com', 'e.com']

    workload = [records[i][0] for i in random.sample(xrange(len(records)), len(records))]
    # workload = workload[:10]
    print(workload)

    config(channel={'reliable', 'fifo'})
    node_process_ids = list(new(m_Node.Node, num=len(node_ids_sorted)))

    node_descs = []
    for i in range(0, len(node_ids_sorted)):
        id = node_ids_sorted[i]
        process_id = node_process_ids[i]
        ip = node_ips_by_id[node_ids_sorted[i]]
        node_descs.append((id, process_id, ip))

    output(len(node_descs))
    output(len(node_ids_sorted))
    # output('record_ids_sorted:', record_ids_sorted)
    output('node_ids_sorted:', node_ids_sorted)

    for i in range(0, len(node_ids_sorted)):
        predecessor = node_descs[i - 1]
        successor = node_descs[(i + 1) % len(node_ids_sorted)]
        finger = _get_finger(i, m, node_descs, node_ids_sorted)
        records = _get_records_for_node(i, record_ids_sorted, node_ids_sorted, records_by_id)
        setup(node_process_ids[i], args=(node_descs[i], m, predecessor, successor, finger, records, kde))

    start(node_process_ids)

    resolver_process_id = new(m_Resolver.Resolver)
    setup(resolver_process_id, args=(resolver_process_id, m, node_descs, workload, kde))
    start(resolver_process_id)

    await(False)
